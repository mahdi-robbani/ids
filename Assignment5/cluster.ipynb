{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kmc import *\n",
    "from pca import *\n",
    "from plot import *\n",
    "s = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportion(n, cluster):\n",
    "    \"\"\"\n",
    "    Takes a number (n) and a list of values (cluster)\n",
    "    and returns the proportion of values that in the lsit that match n\n",
    "    \"\"\"\n",
    "    N = len(cluster)\n",
    "    proportion = len(cluster[cluster == n])/N\n",
    "    print(f\"Proportion of {n}: {round(proportion * 100, 2)}%\")\n",
    "    return proportion\n",
    "\n",
    "def get_proportions(numbers, cluster):\n",
    "    \"\"\"\n",
    "    Returns all proportions for a given cluster\n",
    "    \"\"\"\n",
    "    proportions = []\n",
    "    for i in numbers:\n",
    "        p = get_proportion(i, cluster)\n",
    "        proportions.append(p)\n",
    "#     print(f\"Sum: {sum(proportions)}\")\n",
    "    return proportions\n",
    "\n",
    "def get_cluster_proportions(numbers, clusters, prep_data):\n",
    "    \"\"\"\n",
    "    Takes in a list of numbers and clusters.\n",
    "    Returns the proportion of each number for each cluster\n",
    "    \"\"\"\n",
    "    cluster_proportions = []\n",
    "    for i in range(len(clusters)):\n",
    "        print(f\"Cluster: {i+1}\")\n",
    "        cluster = prep_data[clusters[i]][:, 0]\n",
    "        cluster_proportion = get_proportions(numbers, cluster)\n",
    "        cluster_proportions.append(cluster_proportion)\n",
    "    return cluster_proportions\n",
    "\n",
    "def plot_number(means, title):\n",
    "    for i in range(len(means)):\n",
    "        plt.imshow(np.reshape(means[i], (28,28)))\n",
    "        plot_template(title=title + str(i+1), xlabel=\"\", ylabel=\"\", grid = False, equal_axis=False, save = s)\n",
    "\n",
    "def get_prop_plot(k, numbers, data, labels, title):\n",
    "    means = kmean(k, data)\n",
    "    clusters = get_cluster(means, data)\n",
    "    prep_data = np.c_[labels, data]\n",
    "    get_cluster_proportions(numbers, clusters, prep_data)\n",
    "    plot_number(means, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_acc(k, train_x, train_y, test_x, test_y):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(test_x, test_y)\n",
    "    acc = accuracy_score(train_y, model.predict(train_x))\n",
    "    return acc\n",
    "\n",
    "def cross_validate(k, XTrain, YTrain):\n",
    "    '''For a value k, perform 5 fold cross validation for k nearest neighbors'''\n",
    "    loss_list = []\n",
    "    # create indices for CV\n",
    "    cv = KFold(n_splits = 5)\n",
    "    # loop over CV folds\n",
    "    for train, test in cv.split(XTrain):\n",
    "        XTrainCV, XTestCV, YTrainCV, YTestCV = XTrain[train], XTrain[test], YTrain[train], YTrain[test]\n",
    "        lossTest = 1 - get_acc(k, XTrainCV, YTrainCV, XTestCV, YTestCV)\n",
    "        loss_list.append(lossTest)\n",
    "    average_loss = np.mean(loss_list)\n",
    "    return average_loss\n",
    "\n",
    "def find_best_k(k_list, XTrain, YTrain):\n",
    "    '''Given a list of ks, perform 5 fold cross validation for each k and return the best k'''\n",
    "    k_loss = []\n",
    "    for k in k_list:\n",
    "        loss = cross_validate(k, XTrain, YTrain)\n",
    "        k_loss.append(loss)\n",
    "        print(\"Loss for \"+ str(k) + \" neighbors: \" + str(loss))\n",
    "    ind = k_loss.index(min(k_loss))\n",
    "    best_k = k_list[ind]\n",
    "    acc = 1 - min(k_loss)\n",
    "    print(\"====== Results ======\")\n",
    "    print(f\"Best k: {best_k}\\nAccuracy: {acc}\")\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prop_plot_mds(k, numbers, data, labels, dimension, title):\n",
    "    print(\"===============\")\n",
    "    print(f\"{dimension} dimensions:\")\n",
    "    print(\"===============\")\n",
    "    reduced_data, eigenvectors = mds(data, data, dimension)\n",
    "    reduced_means = kmean(k, reduced_data)\n",
    "    clusters = get_cluster(reduced_means, reduced_data)\n",
    "    prep_data = np.c_[labels, reduced_data]\n",
    "    get_cluster_proportions(numbers, clusters, prep_data)\n",
    "    reduced_means = np.array(reduced_means)\n",
    "    means = mds_inv(reduced_means, eigenvectors, dimension)\n",
    "    plot_number(means, title=str(dimension) + title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mds_acc(dim, k_list, data, labels):\n",
    "    print(\"===============\")\n",
    "    print(f\"{dim} dimensions:\")\n",
    "    print(\"===============\")\n",
    "    reduced_data, _ = mds(data, data, dim)\n",
    "    find_best_k(k_list, reduced_data, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
