{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kmc import *\n",
    "from plot import *\n",
    "\n",
    "digits = np.loadtxt(\"data/MNIST_179_digits.txt\")\n",
    "labels = np.loadtxt(\"data/MNIST_179_labels.txt\")\n",
    "s = True\n",
    "#prep_digits = np.c_[labels, digits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proportion(n, cluster):\n",
    "    \"\"\"\n",
    "    Takes a number (n) and a list of values (cluster)\n",
    "    and returns the proportion of values that in the lsit that match n\n",
    "    \"\"\"\n",
    "    N = len(cluster)\n",
    "    proportion = len(cluster[cluster == n])/N\n",
    "    print(f\"Proportion of {n}: {round(proportion * 100, 2)}%\")\n",
    "    return proportion\n",
    "\n",
    "def get_proportions(numbers, cluster):\n",
    "    \"\"\"\n",
    "    Returns all proportions for a given cluster\n",
    "    \"\"\"\n",
    "    proportions = []\n",
    "    for i in numbers:\n",
    "        p = get_proportion(i, cluster)\n",
    "        proportions.append(p)\n",
    "#     print(f\"Sum: {sum(proportions)}\")\n",
    "    return proportions\n",
    "\n",
    "def get_cluster_proportions(numbers, clusters, prep_data):\n",
    "    \"\"\"\n",
    "    Takes in a list of numbers and clusters.\n",
    "    Returns the proportion of each number for each cluster\n",
    "    \"\"\"\n",
    "    cluster_proportions = []\n",
    "    for i in range(len(clusters)):\n",
    "        print(f\"Cluster: {i+1}\")\n",
    "        cluster = prep_data[clusters[i]][:, 0]\n",
    "        cluster_proportion = get_proportions(numbers, cluster)\n",
    "        cluster_proportions.append(cluster_proportion)\n",
    "    return cluster_proportions\n",
    "\n",
    "def plot_number(means, title):\n",
    "    for i in range(len(means)):\n",
    "        plt.imshow(np.reshape(means[i], (28,28)))\n",
    "        plot_template(title=title + str(i+1), xlabel=\"\", ylabel=\"\", grid = False, equal_axis=False, save = s)\n",
    "\n",
    "def get_prop_plot(k, numbers, data, labels, title):\n",
    "    means = kmean(k, data)\n",
    "    clusters = get_cluster(means, data)\n",
    "    prep_data = np.c_[labels, data]\n",
    "    get_cluster_proportions(numbers, clusters, prep_data)\n",
    "    plot_number(means, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 1\n",
      "Proportion of 1: 83.33%\n",
      "Proportion of 7: 8.94%\n",
      "Proportion of 9: 7.72%\n",
      "Cluster: 2\n",
      "Proportion of 1: 85.35%\n",
      "Proportion of 7: 11.62%\n",
      "Proportion of 9: 3.03%\n",
      "Cluster: 3\n",
      "Proportion of 1: 0.15%\n",
      "Proportion of 7: 48.46%\n",
      "Proportion of 9: 51.4%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Exercise 9a\n",
    "numbers = [1,7,9]\n",
    "get_prop_plot(3, numbers, digits, labels, \"Raw data Cluster \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 9b\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_acc(k, train_x, train_y, test_x, test_y):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(test_x, test_y)\n",
    "    acc = accuracy_score(train_y, model.predict(train_x))\n",
    "    return acc\n",
    "\n",
    "def cross_validate(k, XTrain, YTrain):\n",
    "    '''For a value k, perform 5 fold cross validation for k nearest neighbors'''\n",
    "    loss_list = []\n",
    "    # create indices for CV\n",
    "    cv = KFold(n_splits = 5)\n",
    "    # loop over CV folds\n",
    "    for train, test in cv.split(XTrain):\n",
    "        XTrainCV, XTestCV, YTrainCV, YTestCV = XTrain[train], XTrain[test], YTrain[train], YTrain[test]\n",
    "        lossTest = 1 - get_acc(k, XTrainCV, YTrainCV, XTestCV, YTestCV)\n",
    "        loss_list.append(lossTest)\n",
    "    average_loss = np.mean(loss_list)\n",
    "    return average_loss\n",
    "\n",
    "def find_best_k(k_list, XTrain, YTrain):\n",
    "    '''Given a list of ks, perform 5 fold cross validation for each k and return the best k'''\n",
    "    k_loss = []\n",
    "    for k in k_list:\n",
    "        loss = cross_validate(k, XTrain, YTrain)\n",
    "        k_loss.append(loss)\n",
    "        print(\"Loss for \"+ str(k) + \" neighbors: \" + str(loss))\n",
    "    ind = k_loss.index(min(k_loss))\n",
    "    best_k = k_list[ind]\n",
    "    acc = 1 - min(k_loss)\n",
    "    print(\"====== Results ======\")\n",
    "    print(f\"Best k: {best_k}\\nAccuracy: {acc}\")\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for 1 neighbors: 0.05577777777777777\n",
      "Loss for 3 neighbors: 0.05822222222222222\n",
      "Loss for 5 neighbors: 0.061111111111111116\n",
      "Loss for 7 neighbors: 0.06644444444444446\n",
      "Loss for 9 neighbors: 0.06577777777777778\n",
      "Loss for 11 neighbors: 0.06844444444444446\n",
      "====== Results ======\n",
      "Best k: 1\n",
      "Accuracy: 0.9442222222222222\n"
     ]
    }
   ],
   "source": [
    "k_list = [1, 3, 5, 7, 9, 11]\n",
    "best_k = find_best_k(k_list, digits, labels)\n",
    "# best_acc = get_acc(best_k, digits, labels, digits, labels)\n",
    "# print(f\"Best K: {best_k} Accuracy: {best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Exercise 9b #MY IMPLEMENTION DOES WORK, CHECK LATER\n",
    "# from knn import *\n",
    "# k_list = [1, 3, 5, 7, 9, 11]\n",
    "# find_best_k(k_list, digits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"MY KNN PREDICT FUNCTION RETURNS THE WRONG SIZE ARRAY\"\"\"\n",
    "# #accuracy_score(labels, knn_predict(digits, 3, digits, labels))\n",
    "# print(knn_predict(digits, 5, digits, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exercise 10 a\n",
    "from pca import *\n",
    "e_vec, e_val = pca(digits)\n",
    "cum_variance = np.cumsum(e_val/sum(e_val)) * 100\n",
    "count = list(range(1, len(e_val)+1))\n",
    "plt.plot(count, cum_variance)\n",
    "plot_template(title= 'Cumulative Variance versus Principal Components of Digits',\n",
    "             xlabel='Number of Principcal Components',\n",
    "             ylabel='Percentage of Variance Captured',\n",
    "             equal_axis=False, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "1 dimensions:\n",
      "===============\n",
      "Cluster: 1\n",
      "Proportion of 1: 5.48%\n",
      "Proportion of 7: 46.97%\n",
      "Proportion of 9: 47.55%\n",
      "Cluster: 2\n",
      "Proportion of 1: 95.7%\n",
      "Proportion of 7: 3.49%\n",
      "Proportion of 9: 0.81%\n",
      "Cluster: 3\n",
      "Proportion of 1: 0.0%\n",
      "Proportion of 7: 49.01%\n",
      "Proportion of 9: 50.99%\n",
      "===============\n",
      "20 dimensions:\n",
      "===============\n",
      "Cluster: 1\n",
      "Proportion of 1: 83.33%\n",
      "Proportion of 7: 8.94%\n",
      "Proportion of 9: 7.72%\n",
      "Cluster: 2\n",
      "Proportion of 1: 86.22%\n",
      "Proportion of 7: 11.22%\n",
      "Proportion of 9: 2.55%\n",
      "Cluster: 3\n",
      "Proportion of 1: 0.15%\n",
      "Proportion of 7: 48.46%\n",
      "Proportion of 9: 51.39%\n",
      "===============\n",
      "200 dimensions:\n",
      "===============\n",
      "Cluster: 1\n",
      "Proportion of 1: 83.33%\n",
      "Proportion of 7: 8.94%\n",
      "Proportion of 9: 7.72%\n",
      "Cluster: 2\n",
      "Proportion of 1: 85.35%\n",
      "Proportion of 7: 11.62%\n",
      "Proportion of 9: 3.03%\n",
      "Cluster: 3\n",
      "Proportion of 1: 0.15%\n",
      "Proportion of 7: 48.46%\n",
      "Proportion of 9: 51.4%\n"
     ]
    }
   ],
   "source": [
    "# Exercise 10b\n",
    "from pca import *\n",
    "\n",
    "def get_prop_plot_mds(k, numbers, data, labels, dimension, title):\n",
    "    print(\"===============\")\n",
    "    print(f\"{dimension} dimensions:\")\n",
    "    print(\"===============\")\n",
    "    reduced_data, eigenvectors = mds(data, data, dimension)\n",
    "    reduced_means = kmean(k, reduced_data)\n",
    "    clusters = get_cluster(reduced_means, reduced_data)\n",
    "    prep_data = np.c_[labels, reduced_data]\n",
    "    get_cluster_proportions(numbers, clusters, prep_data)\n",
    "    reduced_means = np.array(reduced_means)\n",
    "    means = mds_inv(reduced_means, eigenvectors, dimension)\n",
    "    #plot_number(means, title=str(dimension) + title)\n",
    "\n",
    "dimensions = [1, 20, 200]\n",
    "s = False\n",
    "\n",
    "for i in dimensions:\n",
    "    get_prop_plot_mds(3, numbers, digits, labels, i, \" dimensions Cluster \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============\n",
      "20 dimensions:\n",
      "===============\n",
      "Loss for 1 neighbors: 0.04977777777777779\n",
      "Loss for 3 neighbors: 0.05311111111111111\n",
      "Loss for 5 neighbors: 0.05444444444444445\n",
      "Loss for 7 neighbors: 0.05311111111111113\n",
      "Loss for 9 neighbors: 0.057777777777777775\n",
      "Loss for 11 neighbors: 0.061555555555555544\n",
      "====== Results ======\n",
      "Best k: 1\n",
      "Accuracy: 0.9502222222222222\n",
      "===============\n",
      "200 dimensions:\n",
      "===============\n",
      "Loss for 1 neighbors: 0.05577777777777777\n",
      "Loss for 3 neighbors: 0.057777777777777775\n",
      "Loss for 5 neighbors: 0.06066666666666667\n",
      "Loss for 7 neighbors: 0.06555555555555556\n",
      "Loss for 9 neighbors: 0.06533333333333333\n",
      "Loss for 11 neighbors: 0.06733333333333333\n",
      "====== Results ======\n",
      "Best k: 1\n",
      "Accuracy: 0.9442222222222222\n"
     ]
    }
   ],
   "source": [
    "# Exercise 10c\n",
    "#k_list = [1, 3, 5, 7, 9, 11]\n",
    "def mds_acc(dim, k_list, data, labels):\n",
    "    print(\"===============\")\n",
    "    print(f\"{dim} dimensions:\")\n",
    "    print(\"===============\")\n",
    "    reduced_data, _ = mds(data, data, dim)\n",
    "    #print(reduced_data)\n",
    "#     best_k = find_best_k(k_list, reduced_data, labels)\n",
    "#     best_acc = get_acc(best_k, reduced_data, labels, reduced_data, labels)\n",
    "    find_best_k(k_list, reduced_data, labels)\n",
    "    #print(f\"Best K: {best_k} Accuracy: {best_acc}\")\n",
    "\n",
    "for i in dimensions[1:]:\n",
    "    mds_acc(i, k_list, digits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 784)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, e = mds(digits, digits, 1)\n",
    "m = kmean(3, r)\n",
    "m = np.array(m)\n",
    "np.shape(mds_inv(m, e, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_k = find_best_k(k_list, r, labels)\n",
    "# best_acc = get_acc(best_k, r, labels, r, labels)\n",
    "# print(f\"Best K: {best_k} Accuracy: {best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mds(target, source, d):\n",
    "    \"\"\"\n",
    "    Transform a target using the eigenvectors of the source\n",
    "    \"\"\"\n",
    "    eigenvectors, eigenvalues = pca(source) # calculate eigenvectors\n",
    "    e_d = eigenvectors[:, :d] # select first d eigenvectors\n",
    "    target = e_d.T @ target.T # transpose EV to d*D matrix, transpose data to D*N matrix, get d*N matrix\n",
    "    target = target.T #transpose to N*d matrix\n",
    "    return target, eigenvectors\n",
    "\n",
    "def mds_inv(reduced_data, eigenvector, d):\n",
    "    \"\"\"Transfoms a reduced data set back to the original size using the original eigenvectors\"\"\"\n",
    "    eigen_inv = np.linalg.inv(eigenvector) #calculat inverse\n",
    "    e_inv = eigenvector[:, :d] #get desired number of dimensions\n",
    "    data = e_inv @ reduced_data.T # D*d @ d*N\n",
    "    data = data.T # convert to N*D\n",
    "    return data\n",
    "\n",
    "r, e = mds(digits, digits, 1)\n",
    "# e_inv = np.linalg.inv(e)\n",
    "# e_inv = e_inv[:, :1]\n",
    "# np.shape(e_inv)\n",
    "d = mds_inv(r, e, 1)\n",
    "np.shape(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1,7,9]\n",
    "get_prop_plot(3, numbers, digits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = KNeighborsClassifier(n_neighbors=11)\n",
    "# N.fit(digits, labels)\n",
    "# accuracy_score(labels, N.predict(digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x , u = np.unique(labels, return_counts=True)\n",
    "np.where(u == max(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(clusters)):\n",
    "#     print(f\"Cluster: {i+1}\")\n",
    "#     get_proportions(numbers, prep_digits[clusters[i]][:, 0]) #get proportions for first column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = prep_digits[clusters[0]][:, 0]\n",
    "get_proportions([1,3,7], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x[x == 7])/len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_proportion(7, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old ex 9a\n",
    "\n",
    "from kmc import *\n",
    "numbers = [1,7,9]\n",
    "means = kmean(3, digits)\n",
    "clusters = get_cluster(means, digits)\n",
    "get_cluster_proportions(numbers, clusters, prep_digits)\n",
    "plot_number(means)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
